@inproceedings{yao2023korc,
  author = {Zijun Yao* and \textbf{Yantao Liu}* and Xin Lv and Shulin Cao and Jifan Yu and Juanzi Li and Lei Hou},
  title = {KoRC: Knowledge Oriented Reading Comprehension Benchmark for Deep Text Understanding},
  booktitle = "Findings of the Association for Computational Linguistics: ACL 2023",
  month = jul,
  
  address = "Toronto, Canada",
  publisher = "Association for Computational Linguistics",
  url = "https://aclanthology.org/2023.findings-acl.743",
  doi = "10.18653/v1/2023.findings-acl.743",
  pages = "11689--11707",
}

@unpublished{liu2024untangle,
  author = {\textbf{Yantao Liu}* and Zijun Yao* and Xin Lv and Yuchen Fan and Shulin Cao and Jifan Yu and Lei Hou and Juanzi Li},
  title = {Untangle the KNOT: Interweaving Conflicting Knowledge and Reasoning Skills in Large Language Models},
  note = {Accepted by COLING 2024},
  
}

@unpublished{fan2024evaluating,
  author = {Yuchen Fan* and \textbf{Yantao Liu}* and Zijun Yao and Jifan Yu and Lei Hou and Juanzi Li},
  title = {Evaluating Generative Language Models in Information Extraction as Subjective Question Correction},
  note = {Accepted by COLING 2024},
  
}

@unpublished{yu2024kola,
  author = {Jifan Yu* and Xiaozhi Wang* and xxx other authors and \textbf{Yantao Liu} and xxx other authors and Zhiyuan Liu and Bin Xu and Jie Tang and Juanzi Li},
  title = {KoLA: Carefully Benchmarking World Knowledge of Large Language Models},
  note = {Accepted by ICLR 2024},
  
}

@inproceedings{liu2022graph,
  author = {\textbf{Yantao Liu} and Luca Rossi and Andrea Torsello},
  title = {A Novel Graph Kernel Based on the Wasserstein Distance and Spectral Signatures},
  booktitle = {Joint IAPR International Workshops on Statistical Techniques in Pattern Recognition (SPR) and Structural and Syntactic Pattern Recognition (SSPR)},
  pages = {122--131},
  publisher = {Springer International Publishing},
  year = {2022},
}

@article{liu2023context,
  author = {\textbf{Yantao Liu} and Zixuan Li and Xiaolong Jin and Long Bai and Saiping Guan and Jiafeng Guo and Xueqi Cheng},
  title = {An In-Context Schema Understanding Method for Knowledge Base Question Answering},
  note = {Submitted to KSEM 2024},
}

@article{ren2023nested,
  title={Nested Event Extraction upon Pivot Element Recogniton},
  author = {Weicheng Ren and Zixuan Li and Xiaolong Jin and Long Bai and Miao Su and \textbf{Yantao Liu} and Saiping Guan and Jiafeng Guo and Xueqi Cheng},
  journal={arXiv preprint arXiv:2309.12960},
  note = {Accepted by COLING 2024},
}

@inproceedings{zhou-etal-2023-context,
    title = "Context-faithful Prompting for Large Language Models",
    author = "Zhou, Wenxuan  and
      Zhang, Sheng  and
      Poon, Hoifung  and
      Chen, Muhao",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.968",
    doi = "10.18653/v1/2023.findings-emnlp.968",
    pages = "14544--14556",
    abstract = "Large language models (LLMs) encode parametric knowledge about world facts and have shown remarkable performance in knowledge-driven NLP tasks. However, their reliance on parametric knowledge may cause them to overlook contextual cues, leading to incorrect predictions in context-sensitive NLP tasks (e.g., knowledge acquisition tasks). In this paper, we seek to assess and enhance LLMs{'} contextual faithfulness in two aspects: knowledge conflict and prediction with abstention. We demonstrate that LLMs{'} faithfulness can be significantly improved using carefully designed prompting strategies. In particular, we identify opinion-based prompts and counterfactual demonstrations as the most effective methods. Opinion-based prompts reframe the context as a narrator{'}s statement and inquire about the narrator{'}s opinions, while counterfactual demonstrations use instances containing false facts to improve faithfulness in knowledge conflict situations. Neither technique requires additional training. We conduct experiments on three datasets of two standard NLP tasks, machine reading comprehension and relation extraction, and the results demonstrate significant improvement in faithfulness to contexts. Code and data are released at https://github.com/wzhouad/context-faithful-llm.",
}

@article{shi2023trusting,
  title={Trusting your evidence: Hallucinate less with context-aware decoding},
  author={Shi, Weijia and Han, Xiaochuang and Lewis, Mike and Tsvetkov, Yulia and Zettlemoyer, Luke and Yih, Scott Wen-tau},
  journal={arXiv preprint arXiv:2305.14739},
  year={2023}
}
